<!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
<p>HGRL Tutorial @ ECML-PKDD2022<!-- favicon 
    <link href="favicon.png" rel=icon>--><!-- web-fonts --><!-- Bootstrap --><!-- Style CSS --><!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries --><!-- WARNING: Respond.js doesn't work if you view the page via file:// --><!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]--><!-- Page Preloader --><!-- Navigation --></p>

<p>Toggle navigation <!--<a class="navbar-brand page-scroll" href="#page-top"><img src="img/logo.png" alt=""></a>--></p>
<!-- Collect the nav links, forms, and other content for toggling -->

<ul><!-- Hidden li included to remove active class from about link when scrolled up past about section -->
	<li><a class="page-scroll" href="#section-intro">Overview</a></li>
	<!-- <li><a class="page-scroll" href="#section-cfp">Cfp</a></li>
<li><a class="page-scroll" href="#section-date">DATES</a></li>
<li><a class="page-scroll" href="#section-ajenda">Program</a></li>
<li><a class="page-scroll" href="#section-speaker">Speakers</a></li>
<li><a class="page-scroll" href="#section-papers">Accepted Papers</a></li>-->
	<li><a class="page-scroll" href="#section-syllabus">Syllabus</a></li>
	<li><a class="page-scroll" href="#section-organizer">Presenters</a></li>
</ul>
<!-- /.navbar-collapse --><!-- /.container --><!-- .nav -->

<h1>Hyperbolic Graph Representation Learning: A Tutorial</h1>
<!-- <h2 style="color:#FFFFFF;"><b>Keywords: DNNs, DRL, GNNs, AutoML, Adversarial Attacks, Trustworthy Recommendations</b> </h2>>
	   <!-- <h2 style="color:#FFFFFF;"><b>Aug 20 20:00 – 2:00 (Next day) Montreal Time (UTC-4) </b> </h2>>
            <!--<div class="event-date">9:00 - 11:45 PM, April 16, 2021 (EST time)</div>--><!--
	    <h2 style="color:#FFFFFF;"><b>Zoom Link:  <a href="https://zoom.virtualchair.net/ijcai9/V9zt6w">https://zoom.virtualchair.net/ijcai9/V9zt6w </a ></b> </h2>

		<h2 style="color:#FFFFFF;"><b>Introduction</b> </h2>
	    <h2 style="color:#FFFFFF;"><b>Fundamentals of Deep Recommender Systems</b> </h2>
	    <h2 style="color:#FFFFFF;"><b>Reinforcement Learning for Recommender Systems</b> </h2>
	    <h2 style="color:#FFFFFF;"><b>Graph Neural Network for Recommendations</b> </h2>
	    <h2 style="color:#FFFFFF;"><b>Automated Machine Learning for Recommender Systems</b>  </h2>
            <h2 style="color:#FFFFFF;"><b>Adversarial Attacks for Recommender Systems </b>  </h2>
	    --><!--<h2 style="color:#0F1555;"><b><a href="https://msu.zoom.us/j/94465359383">Zoom Link to Tutorial</a></b></h2>--><!--<div class="event-date">Summit 1 - Ground Level, Egan, Anchorage, Alaska - USA</div>
            <!--<p class="lead">It's a tag line, where you can write a key point of your idea. It is a long established fact that a reader will be distracted by the readable content of a page when looking at its layout.</p>
            <button type="button" class="btn btn-default btn-lg">STAY IN THE LOOP</button>--><!-- .Jumbotron--><!-- Introduction Section -->

<h1 style="text-align:center"><span style="font-size:26px"><strong>Overview</strong></span></h1>

<p>Graph-structured data are widespread in real-world applications, such as social networks, recommender systems, knowledge graphs, chemical molecules, etc. Despite the success of Euclidean space for graph-related learning tasks, its ability to model complex patterns is essentially constrained by its polynomially growing capacity. Recently, hyperbolic spaces have emerged as a promising alternative for processing graph data with tree-like structure or power-law distribution, owing to their exponential growth property. Different from the Euclidean space which expands polynomially, the hyperbolic space grows exponentially which makes it gains natural advantages in abstracting tree-like or scale-free graphs with hierarchical organizations.</p>

<p>In this tutorial, we will give an introduction to this emerging field in graph representation learning, with the express purpose of being accessible to all audiences. We first give a brief introduction to graph representation learning as well as some preliminary Riemannian and hyperbolic geometry. We then will comprehensively revisit the hyperbolic embedding techniques including hyperbolic shallow models and hyperbolic neural networks. In addition, we will give the technical details of the current hyperbolic graph neural networks, by unifying them into a general framework and summarizing the variants of each component. Moreover, we will introduce a series of related applications in a variety of fields. In the last part, we will discuss several advanced topics about hyperbolic geometry for graph representation learning, which potentially serve as guidelines for further flourishing the non-Euclidean graph learning community.</p>

<h2 style="text-align:center"><span style="font-size:26px"><strong>Syllabus </strong></span></h2>

<p>The topics of this tutorial include (but are not limited to) the following:</p>

<ol>
	<li><strong>Introduction <strong><!--<a href="slides/Intro.pdf">[Slides]</a> <a href="https://youtu.be/75L3l_J-tq0">[Video]</a></li> --> </strong></strong>

	<ul>
		<li><strong><strong>1.1 An overview of graph representation learning</strong></strong></li>
		<li><strong><strong>1.2 Brief introduction to Riemannian geometry</strong></strong></li>
		<li><strong><strong>1.3 Motivation of Hyperbolic Graph Representation Learning（HGRL）</strong></strong></li>
		<li><strong><strong>1.4 QA&amp;Break</strong></strong></li>
	</ul>
	<strong><strong> </strong></strong></li>
	<li><strong><strong><strong>Hyperbolic Models<strong> </strong></strong></strong></strong>
	<ul>
		<li><strong><strong><strong><strong>2.1 Hyperbolic shallow models</strong></strong></strong></strong></li>
		<li><strong><strong><strong><strong>2.2 Hyperbolic neural networks </strong></strong></strong></strong></li>
		<li><strong><strong><strong><strong>2.3 Hyperbolic graph neural networks </strong></strong></strong></strong></li>
		<li><strong><strong><strong><strong>2.4 QA&amp;Break</strong></strong></strong></strong></li>
	</ul>
	<strong><strong><strong><strong> </strong></strong></strong></strong></li>
	<li><strong><strong><strong><strong>Applications </strong></strong></strong></strong>
	<ul>
		<li><strong><strong><strong><strong>3.1 HGRL for recommender systems</strong></strong></strong></strong></li>
		<li><strong><strong><strong><strong>3.2 HGRL for knowledge graph</strong></strong></strong></strong></li>
		<li><strong><strong><strong><strong>3.3 HGRL for chemistry and biology</strong></strong></strong></strong></li>
		<li><strong><strong><strong><strong>3.4 HGRL for other applications</strong></strong></strong></strong></li>
		<li><strong><strong><strong><strong>3.5 QA&amp;Break</strong></strong></strong></strong></li>
	</ul>
	<strong><strong><strong><strong> </strong></strong></strong></strong></li>
	<li><strong><strong><strong><strong>Advanced Topics </strong></strong></strong></strong>
	<ul>
		<li><strong><strong><strong><strong>4.1 Complex Structures</strong></strong></strong></strong></li>
		<li><strong><strong><strong><strong>4.2 Evolving Interactions</strong></strong></strong></strong></li>
		<li><strong><strong><strong><strong>4.3 Geometry-aware Learning</strong></strong></strong></strong></li>
		<li><strong><strong><strong><strong>4.4 Trustworthy and Scalability</strong></strong></strong></strong></li>
		<li><strong><strong><strong><strong>4.5 QA&amp;Break</strong></strong></strong></strong></li>
	</ul>
	<strong><strong><strong><strong> </strong></strong></strong></strong></li>
</ol>

<p><strong><strong><strong>Videos: TBD</strong></strong></strong></p>

<p><strong><strong><strong>Link to ECML-PKDD PKDD2022 official Website: TBA </strong></strong></strong></p>

<p><strong><strong><strong><!-- <a href="https://ecmp-pkdd22.org/tutorials/">https://ecmp-pkdd22.org/tutorials/</a > </div>--> </strong></strong></strong></p>

<p>&nbsp;</p>

<p>&nbsp;</p>

<h1 style="text-align:center"><strong><strong><strong>Presenters</strong></strong></strong></h1>

<p><strong><strong><strong><a href="https://minzhou1900.github.io/"><img alt="Image" class="rounded" src="img/img-min.jpg" /></a> </strong></strong></strong></p>

<h3><strong><strong><strong>Min Zhou Huawei Noah&#39;s Ark Lab </strong></strong></strong></h3>

<ul>
	<li>&nbsp;</li>
	<li>&nbsp;</li>
	<li>&nbsp;</li>
	<li>&nbsp;</li>
</ul>

<p><strong><strong><strong><!-- /.col-sm-6 --> </strong></strong></strong><strong><strong><strong><a href="#"><img alt="Image" class="img-responsive" src="img/img-menglin.jpeg" /></a> </strong></strong></strong></p>

<h3><strong><strong><strong>Menglin Yang Chinese University of Hong Kong </strong></strong></strong></h3>

<ul>
	<li>&nbsp;</li>
	<li>&nbsp;</li>
	<li>&nbsp;</li>
	<li>&nbsp;</li>
</ul>

<p><strong><strong><strong><!-- /.col-sm-6 --> </strong></strong></strong><strong><strong><strong><a href="#"><img alt="Image" class="img-responsive" src="img/img-lujia.jpg" /></a> </strong></strong></strong></p>

<h3><strong><strong><strong>Lujia Pan Huawei Noah&#39;s Ark Lab </strong></strong></strong></h3>

<ul>
	<li>&nbsp;</li>
	<li>&nbsp;</li>
	<li>&nbsp;</li>
	<li>&nbsp;</li>
</ul>

<p><strong><strong><strong><!-- /.col-sm-6 --> </strong></strong></strong><strong><strong><strong><a href="https://www.cse.cuhk.edu.hk/people/faculty/irwin-king"><img alt="Image" class="img-responsive" src="img/img-irwin-king.jpg" /></a> </strong></strong></strong></p>

<h3><strong><strong><strong>Irwin King Chinese University of Hong Kong </strong></strong></strong></h3>

<ul>
	<li>&nbsp;</li>
	<li>&nbsp;</li>
	<li>&nbsp;</li>
	<li>&nbsp;</li>
</ul>

<p><strong><strong><strong><!-- /.col-sm-6 --> </strong></strong></strong><strong><strong><strong><!-- .row --> </strong></strong></strong><strong><strong><strong><!-- /.container --> </strong></strong></strong><strong><strong><strong><!-- .team --> <!-- Presenters’ Biography --> </strong></strong></strong></p>

<h1 style="text-align:center"><span style="font-size:26px">Presenters&rsquo; Biography</span></h1>

<p><strong><strong><strong><a href="https://minzhou1900.github.io/"><strong>Dr. Min Zhou</strong></a></strong></strong></strong> is currently a Principal Research Engineer of Huawei Noah&rsquo;s ARK LAB, Shenzhen, China. She received the B.S. degree in Automation from the University of Science and Technology of China, and the Ph.D. degree from the Industrial Systems Engineering and Management Department, National University of Singapore, respectively. Her interests include pattern mining and machine learning, and their applications in sequence and graph data. Her interests include pattern mining and machine learning, and their applications in sequence and graph data. Her several works were published at top conferences, including KDD, WWW, ICDE, and SIGIR. She co-organized the 1st Workshop on Machine Learning in Software Engineering (MLiSE) @ ECML-PKDD 2021 and serves as Program Chair of several conferences.</p>

<p>&nbsp;</p>

<p><strong><strong><strong><a href="#"><strong>Mr. Menglin Yang</strong> </a></strong></strong></strong>is currently a Ph.D. student in the Department of Computer Science and Engineering, The Chinese University of Hong Kong (CUHK). His research interests include hyperbolic graph learning and machine learning. Besides, he also focus on real-world applications, including recommender systems, knowledge graph, and drug processing. His several works related to hyperbolic graph representation learning were published at recent top conferences, including KDD 2021, WSDM 2022, and WWW 2022.</p>

<p><strong><strong><strong><a href="#"><strong>Ms. Lujia Pan</strong></a> </strong></strong></strong>is the expert at Huawei Noah&rsquo;s Ark Lab, Shenzhen, China. She currently heads the Intelligent operation and maintenance team and is working closely with a group of researchers and engineers on different projects such as fault diagnosis, anomaly detection, and prediction in the ICT(information and communications technology) network. Her research interests are on various issues related to improving the performance and reliability of intelligent operation and maintenance, including representation learning, time series analysis, label denoising, and active learning. In these research areas, she has published more than 20 technical papers in journals and conferences and is the inventor of more than 40 patents. She is currently a part-time PhD student in the Department of Control Systems and Engineering, Xi&rsquo;an Jiaotong University. Before that she received her B.S. and M.S. degrees in information engineering from Chongqing University of Posts and Telecommunications.</p>

<p><strong><strong><strong><a href="https://www.cse.cuhk.edu.hk/people/faculty/irwin-king"><strong>Prof. Irwin King</strong></a>&nbsp;</strong></strong></strong>is the Chair and Professor of Computer Science &amp; Engineering at The Chinese University of Hong Kong. His research interests include machine learning, social computing, AI, web intelligence, data mining, and multimedia information processing. In these research areas, he has over 300 technical publications in journals and conferences. He is an Associate Editor of the Journal of Neural Networks (NN). He is an IEEE Fellow, an ACM Distinguished Member, and a Fellow of the Hong Kong Institute of Engineers (HKIE). He has served as the President of the International Neural Network Society (INNS), General Co-chair of The WebConf 2020, ICONIP 2020, WSDM 2011, RecSys 2013, ACML 2015, and in various capacities in a number of top conferences and societies such as WWW, NIPS, ICML, IJCAI, AAAI, APNNS, etc. He is the recipient of the ACM CIKM2019 Test of Time Award, the ACM SIGIR 2020 Test of Time Award, and the 2020 APNNS Outstanding Achievement Award for his contributions made in social computing with machine learning. In early 2010 while on leave with AT&amp;T Labs Research, San Francisco, he taught classes as a Visiting Professor at UC Berkeley. He received his B.Sc. degree in Engineering and Applied Science from the California Institute of Technology (Caltech), Pasadena, and his M.Sc. and Ph.D. degree in Computer Science from the University of Southern California (USC), Los Angeles.</p>

<p><strong><strong><strong><!-- .container --> </strong></strong></strong><strong><strong><strong><!-- .copyright-section --> </strong></strong></strong><strong><strong><strong> <!-- .footer --> </strong></strong></strong></p>

<p><strong><strong><!-- #main-wrapper --> <!-- jquery --> <!-- Bootstrap --> <!-- Plugin JavaScript --> <!-- Google Maps API Key - Use your own API key to enable the map feature. More information on the Google Maps API can be found at https://developers.google.com/maps/ --> <!---<script src="https://maps.googleapis.com/maps/api/js"></script>---> <!--<script src="js/one-page-nav.js"></script>--> </strong></strong></p>
